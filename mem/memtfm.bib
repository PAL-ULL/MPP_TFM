

@article{ZHOU201132,
title = "Multiobjective evolutionary algorithms: A survey of the state of the art",
journal = "Swarm and Evolutionary Computation",
volume = "1",
number = "1",
pages = "32 - 49",
year = "2011",
issn = "2210-6502",
author = "Aimin Zhou and Bo-Yang Qu and Hui Li and Shi-Zheng Zhao and Ponnuthurai Nagaratnam Suganthan and Qingfu Zhang",
keywords = "Multiobjective optimization, Evolutionary multiobjective optimization, Multiobjective evolutionary algorithms, Multicriteria decision making"
}

@book{pythonDataScience,
 author = {VanderPlas, Jake},
 title = {Python Data Science Handbook: Essential Tools for Working with Data},
 year = {2016},
 edition = {1st},
 publisher = {O'Reilly Media, Inc.}
} 

@book{tmlpython,
 author = {Kirk, Matthew},
 title = {Thoughtful Machine Learning with Python: A Test-Driven Approach},
 year = {2017},
 edition = {2st},
 publisher = {O'Reilly Media, Inc.}
} 


@ARTICLE{Evidence1,
author={Antonio, L.M. and Berenguer, J.A.M. and Coello, C.A.C.},
title={Evolutionary many-objective optimization based on linear assignment problem transformations},
journal={Soft Computing},
year={2018},
pages={1-22},
document_type={Article in Press},
source={Scopus},
}

@ARTICLE{Evidence3,
author={Köksalan, M. and Tezcaner Öztürk, D.},
title={An evolutionary approach to generalized biobjective traveling salesperson problem},
journal={Computers and Operations Research},
year={2017},
volume={79},
pages={304-313},
document_type={Article},
source={Scopus},
}

@ARTICLE{Evidence4,
author={Mashwani, W.K. and Salhi, A.},
title={Multiobjective evolutionary algorithm based on multimethod with dynamic resources allocation},
journal={Applied Soft Computing Journal},
year={2016},
volume={39},
pages={292-309},
document_type={Article},
source={Scopus},
}

@ARTICLE{Marrero,
author = {Alejandro Marrero Díaz},
title = {Desarrollo de Algoritmos Dirigido por Retos}
}

@article{ECML,
 author = {Zhang, Jun and Zhang, Zhi-hui and Lin, Ying and Chen, Ni and Gong, Yue-jiao and Zhong, Jing-hui and Chung, Henry and Li, Yun and Shi, Yu-hui},
 title = {Evolutionary Computation Meets Machine Learning: A Survey},
 journal = {Comp. Intell. Mag.},
 issue_date = {November 2011},
 volume = {6},
 number = {4},
 month = nov,
 year = {2011},
 issn = {1556-603X},
 pages = {68--75},
 numpages = {8},
 acmid = {2773017},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA}
} 

@article{Yoshida2018,
author = {Yoshida, Mari and Hinkley, Trevor and Tsuda, Soichiro and Abul-Haija, Yousef M and McBurney, Roy T and Kulikov, Vladislav and Mathieson, Jennifer S and Galinanes Reyes, Sabrina and Castro, Maria D and Cronin, Leroy},
issn = {2451-9294},
journal = {Chem},
month = {mar},
number = {3},
pages = {533--543},
publisher = {Elsevier},
title = {Using Evolutionary Algorithms and Machine Learning to Explore Sequence Space for the Discovery of Antimicrobial Peptides},
volume = {4},
year = {2018}
}

@ARTICLE{ECML2,
author={Moradi, B.},
title={An intelligent evolutionary computation approach for solving the shortest path problem},
journal={Journal of Multiple-Valued Logic and Soft Computing},
year={2018},
volume={30},
number={4-6},
pages={335-357},
document_type={Article},
source={Scopus},
}

@InProceedings{IBEA,
author="Zitzler, Eckart
and K{\"u}nzli, Simon",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="Indicator-Based Selection in Multiobjective Search",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="832--842",
abstract="This paper discusses how preference information of the decision maker can in general be integrated into multiobjective search. The main idea is to first define the optimization goal in terms of a binary performance measure (indicator) and then to directly use this measure in the selection process. To this end, we propose a general indicator-based evolutionary algorithm (IBEA) that can be combined with arbitrary indicators. In contrast to existing algorithms, IBEA can be adapted to the preferences of the user and moreover does not require any additional diversity preservation mechanism such as fitness sharing to be used. It is shown on several continuous and discrete benchmark problems that IBEA can substantially improve on the results generated by two popular algorithms, namely NSGA-II and SPEA2, with respect to different performance measures.",
}


@article{METCO,
author = {León, Coromoto and Miranda, Gara and Segura, Carlos},
title = {METCO: A PARALLEL PLUGIN-BASED FRAMEWORK FOR MULTI-OBJECTIVE OPTIMIZATION},
journal = {International Journal on Artificial Intelligence Tools},
volume = {18},
number = {04},
pages = {569-588},
year = {2009},
}

@article{LML,
author = {Silver, Daniel and Yang, Qiang and Li, Lianghao},
year = {2013},
month = {03},
title = {Lifelong Machine Learning Systems: Beyond Learning Algorithms},
booktitle = {AAAI Spring Symposium - Technical Report}
}

@article{MMKP1,
abstract = {In this paper, we solve instances of the multiobjective multiconstraint (or multidimensional) knapsack problem (MOMCKP) from the literature, with three objective functions and three constraints. We use exact as well as approximate algorithms. The exact algorithm is a properly modified version of the multicriteria branch and bound (MCBB) algorithm, which is further customized by suitable heuristics. Three branching heuristics and a more general purpose composite branching and construction heuristic are devised. Comparison is made to the published results from another exact algorithm, the adaptive $\epsilon$-constraint method [Laumanns, M., Thiele, L., Zitzler, E., 2006. An efficient, adaptive parameter variation scheme for Metaheuristics based on the epsilon-constraint method. European Journal of Operational Research 169, 932-942], using the same data sets. Furthermore, the same problems are solved using standard multiobjective evolutionary algorithms (MOEA), namely, the SPEA2 and the NSGAII. The results from the exact case show that the branching heuristics greatly improve the performance of the MCBB algorithm, which becomes faster than the adaptive $\epsilon$ -constraint. Regarding the performance of the MOEA algorithms in the specific problems, SPEA2 outperforms NSGAII in the degree of approximation of the Pareto front, as measured by the coverage metric (especially for the largest instance). {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Florios, K. and Mavrotas, G. and Diakoulaki, D.},
journal = {European Journal of Operational Research},
mendeley-groups = {MMKP},
number = {1},
pages = {14--21},
title = {{Solving multiobjective, multiconstraint knapsack problems using mathematical programming and evolutionary algorithms}},
volume = {203},
year = {2010}
}

@article{MMKP2,
abstract = {The knapsack problem (KP) and its multidimensional version (MKP) are basic problems in combinatorial optimization. In this paper, we consider their multiobjective extension (MOKP and MOMKP), for which the aim is to obtain or approximate the set of efficient solutions. In the first step, we classify and briefly describe the existing works that are essentially based on the use of metaheuristics. In the second step, we propose the adaptation of the two-phase Pareto local search (2PPLS) to the resolution of the MOMKP. With this aim, we use a very large scale neighborhood in the second phase of the method, that is the PLS. We compare our results with state-of-the-art results and show that the results we obtained were never reached before by heuristics for biobjective instances. Finally, we consider the extension to three-objective instances. {\textcopyright} 2012 International Federation of Operational Research Societies.},
author = {Lust, T. and Teghem, J.},
journal = {International Transactions in Operational Research},
mendeley-groups = {MMKP},
number = {4},
pages = {495--520},
title = {{The multiobjective multidimensional knapsack problem: A survey and a new approach}},
volume = {19},
year = {2012}
}

@article{MMKP3,
abstract = {The objective of this paper is to present an interactive procedure for the multiobjective multidimensional 0-1 knapsack problem that takes into consideration the incorporation of fuzzy goals of the decision maker, that is easy to use since it requires from the decision maker to handle only one parameter, namely, the aspiration level of each objective, and that is fast and can treat our problem as a usual 0-1 knapsack problem using already available software, namely, the primal effective gradient method, used primarily to solve the large-scale cases. To get some statistics on the behavior of the algorithm, a number of randomly generated simulation of problems is solved. From our numerical experience, it is possible to conclude that our proposed method is a worthwhile alternative to existing methods from a practical point of view. Copyright {\textcopyright} 1997 Elsevier Science B.V. All rights reserved.},
author = {Abboud, N.J. and Sakawa, M. and Inuiguchi, M.},
journal = {Fuzzy Sets and Systems},
mendeley-groups = {MMKP},
number = {1},
pages = {1--14},
title = {{A fuzzy programming approach to multiobjective multidimensional 0-1 knapsack problems}},
volume = {86},
year = {1997}
}

@article{tdd,
 author = {Desai, Chetan and Janzen, David and Savage, Kyle},
 title = {A Survey of Evidence for Test-driven Development in Academia},
 journal = {SIGCSE Bull.},
 issue_date = {June 2008},
 volume = {40},
 number = {2},
 month = jun,
 year = {2008},
 issn = {0097-8418},
 pages = {97--101},
 numpages = {5},
 acmid = {1383644},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {empirical survey, pedagogy, test-driven development}
} 

@article{tdd2,
author = {Bissi, Wilson and Neto, Adolfo and Claudia Figueiredo Pereira Emer, Maria},
year = {2016},
month = {02},
title = {The Effects of Test Driven Development on Internal Quality, External Quality and Productivity: A systematic review},
volume = {74},
booktitle = {Information and Software Technology}
}




@article{Seljak2009,
abstract = {In this paper, we introduce a computer-based method for menu planning, which applies evolutionary computation. First, we formalize the n-day menu-planning problem, decomposing it into several sub-problems at the daily-menu and meal-planning level. We reduce the problem to a multi-dimensional knapsack problem. Then, we define an evolutionary algorithm that quickly finds a diverse set of feasible solutions (i.e. optimal menus) with the optimum objective functions' values, without examining all the possibilities. As the problem is constrained, infeasible solutions need to be repaired in order to direct the "evolution" towards the feasible regions. We present greedy repairing methods that slightly differ at the global level and the sub-problems' levels. At the meal-planning level, we couple repairing with linear programming to balance infeasible meals. We conclude the paper with the presentation of empirical results, which showed that the evolutionary method may outperform a human. A computer was able to find the Pareto-optimal front of 21-day menus with respect to a dietary advice in equal or less time than a human professional, who designed a daily menu. However, the human factor is still important in the last stage, when a solution has to be selected from the Pareto front. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Seljak, Barbara Korou{\v{s}}i{\'{c}}},
journal = {Journal of Food Composition and Analysis},
keywords = {Computer-based menu planning,Dietary recommendations and guidelines,Evolutionary computation,Food composition,Linear programming,Multi-objective and multi-constraint optimization,Nutrient balancing,Optimal nutrition,Pareto-optimal solutions},
number = {5},
pages = {414--420},
title = {{Computer-based dietary menu planning}},
volume = {22},
year = {2009}
}


@article{obl,
abstract = {Opposition-based learning as a new scheme for machine intelligence is introduced. Estimates and counter-estimates, weights and opposite weights, and actions versus counter-actions are the foundation of this new approach. Examples are provided. Possibilities for extensions of existing learning algorithms are discussed. Preliminary results are provided},
author = {Tizhoosh, H R},
doi = {10.1109/CIMCA.2005.1631345},
file = {:C$\backslash$:/Users/Alejandro/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tizhoosh - 2005 - Opposition-Based Learning A New Scheme for Machine Intelligence.pdf:pdf},
isbn = {0-7695-2504-0},
journal = {Computational Intelligence for Modelling, Control and Automation, 2005 and International Conference on Intelligent Agents, Web Technologies and Internet Commerce, International Conference on},
keywords = {estimation theory,learning (artificial intelligence),machine intelligence,opposition-based learning,optimisation,search problems},
pages = {695--701},
title = {{Opposition-Based Learning: A New Scheme for Machine Intelligence}},
volume = {1},
year = {2005}
}

@Article{Segredo2017,
author="Segredo, Eduardo
and Paechter, Ben
and Segura, Carlos
and Gonz{\'a}lez-Vila, Carlos I.",
title="On the comparison of initialisation strategies in differential evolution for large scale optimisation",
journal="Optimization Letters",
year="2017",
pages="1--14",
abstract="Differential Evolution (de) has shown to be a promising global optimisation solver for continuous problems, even for those with a large dimensionality. Different previous works have studied the effects that a population initialisation strategy has on the performance of de when solving large scale continuous problems, and several contradictions have appeared with respect to the benefits that a particular initialisation scheme might provide. Some works have claimed that by applying a particular approach to a given problem, the performance of de is going to be better than using others. In other cases however, researchers have stated that the overall performance of de is not going to be affected by the use of a particular initialisation method. In this work, we study a wide range of well-known initialisation techniques for de. Taking into account the best and worst results, statistically significant differences among considered initialisation strategies appeared. Thus, with the aim of increasing the probability of appearance of high-quality results and/or reducing the probability of appearance of low-quality ones, a suitable initialisation strategy, which depends on the large scale problem being solved, should be selected.",
issn="1862-4480",
}

@ARTICLE{GRASP,
author={Díaz, J.A. and Luna, D.E. and Camacho-Vallejo, J.-F. and Casas-Ramírez, M.-S.},
title={GRASP and hybrid GRASP-Tabu heuristics to solve a maximal covering location problem with customer preference ordering},
journal={Expert Systems with Applications},
year={2017},
volume={82},
pages={67-76},
document_type={Article},
source={Scopus},
}
@ARTICLE{SA,
author={Gerber, M. and Bornn, L.},
title={Improving simulated annealing through derandomization},
journal={Journal of Global Optimization},
year={2017},
volume={68},
number={1},
pages={189-217},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE1,
author={Zheng, L.M. and Zhang, S.X. and Tang, K.S. and Zheng, S.Y.},
title={Differential evolution powered by collective information},
journal={Information Sciences},
year={2017},
volume={399},
pages={13-29},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE2,
author={Fu, C.M. and Jiang, C. and Chen, G.S. and Liu, Q.M.},
title={An adaptive differential evolution algorithm with an aging leader and challengers mechanism},
journal={Applied Soft Computing Journal},
year={2017},
volume={57},
pages={60-73},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE3,
author={Tian, M. and Gao, X. and Dai, C.},
title={Differential evolution with improved individual-based parameter setting and selection strategy},
journal={Applied Soft Computing Journal},
year={2017},
volume={56},
pages={286-297},
document_type={Article},
source={Scopus},
}

@CONFERENCE{CMA,
author={Hajebi, M. and Hoorfar, A. and Bou-Daher, E.},
title={Inverse profiling of inhomogenous buried cylinders with arbitrary cross sections using CMA-ES},
journal={2016 IEEE Antennas and Propagation Society International Symposium, APSURSI 2016 - Proceedings},
year={2016},
pages={863-864},
art_number={7696140},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{COE1,
author={Atashpendar, A. and Dorronsoro, B. and Danoy, G. and Bouvry, P.},
title={A parallel cooperative coevolutionary SMPSO algorithm for multi-objective optimization},
journal={2016 International Conference on High Performance Computing and Simulation, HPCS 2016},
year={2016},
pages={713-720},
art_number={7568405},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{COE2,
author={Hajikolaei, K.H. and Cheng, G.H. and Wang, G.G.},
title={Optimization on Metamodeling-Supported Iterative Decomposition},
journal={Journal of Mechanical Design, Transactions of the ASME},
year={2016},
volume={138},
number={2},
art_number={021401},
document_type={Article},
source={Scopus},
}

@CONFERENCE{COE3,
author={Glorieux, E. and Svensson, B. and Danielsson, F. and Lennartson, B.},
title={Improved constructive cooperative coevolutionary differential evolution for large-scale optimisation},
journal={Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015},
year={2016},
pages={1703-1710},
art_number={7376815},
document_type={Conference Paper},
source={Scopus},
}

@article{OPSO,
abstract = {Particle Swarm Optimization, a population based optimization technique has been used in wide number of application areas to solve optimization problems. This paper presents a new algorithm for initialization of population in standard PSO called Opposition based Particle Swarm Optimization (O-PSO). The performance of proposed initialization algorithm is compared with the existing PSO variants on several benchmark functions and the experimental results reveal that O-PSO outperforms existing approaches to a large extent.},
author = {Jabeen, Hajira and Jalil, Zunera and Baig, Abdul Rauf},
isbn = {9781605585055},
journal = {Proceedings of the 11th annual conference companion on Genetic and evolutionary computation conference - GECCO '09},
keywords = {initialization,opposition based learning,optimization,pso,swarm intelligence},
pages = {2047},
title = {{Opposition based initialization in particle swarm optimization (O-PSO)}},
year = {2009}
}

@article{OPSO2,
abstract = {Particle swarm optimization (PSO) is a stochastic, population-based optimization method, which has been applied successfully to a wide range of problems. However, PSO is computationally expensive and suffers from premature convergence. In this paper, opposition-based learning is used to improve the performance of PSO. The performance of the proposed approaches is investigated and compared with PSO when applied to eight benchmark functions. The experiments conducted show that opposition-based learning improves the performance of PSO.},
author = {Omran, Mahamed G. H. and Al-Sharhan, Salah},
isbn = {978-1-4244-2704-8},
journal = {2008 IEEE Swarm Intelligence Symposium},
number = {1},
pages = {1--6},
title = {{Using opposition-based learning to improve the performance of particle swarm optimization}},
year = {2008}
}

@article{obl2,
abstract = {Evolutionary algorithms (EAs) are well-known optimization approaches to deal with nonlinear and complex problems. However, these population-based algorithms are computationally expensive due to the slow nature of the evolutionary process. This paper presents a novel algorithm to accelerate the differential evolution (DE). The proposed opposition-based DE (ODE) employs opposition-based learning (OBL) for population initialization and also for generation jumping. In this work, opposite numbers have been utilized to improve the convergence rate of DE. A comprehensive set of 58 complex benchmark functions including a wide range of dimensions is employed for experimental verification. The influence of dimensionality, population size, jumping rate, and various mutation strategies are also investigated. Additionally, the contribution of opposite numbers is empirically verified. We also provide a comparison of ODE to fuzzy adaptive DE (FADE). Experimental results confirm that the ODE outperforms the original DE and FADE in terms of convergence speed and solution accuracy.},
author = {Rahnamayan, Shahryar and Tizhoosh, Hamid R. and Salama, Magdy M.},
isbn = {9783540688273},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
number = {1},
pages = {155--171},
title = {{Opposition-based differential evolution}},
volume = {143},
year = {2008}
}

@article{comparison,
abstract = {This paper focuses on the three very similar evolutionary algorithms,$\backslash$nGenetic Algorithm (GA), Particle Swarm Optimization (PSO), and Differential$\backslash$nEvolution (DE). While GA is more suitable for discrete optimization,$\backslash$nPSO and DE are more natural for continuous optimization. The paper$\backslash$nfirst gives a brief introduction to the three EA techniques to highlight$\backslash$nthe common computational procedures. The general observations on$\backslash$nthe similarities and differences among the three algorithms based$\backslash$non computational steps are discussed. Contrasts are given on some$\backslash$nbasic observations on performances of algorithms. Summary of relevant$\backslash$nliteratures on job shop, flexible job shop, vehicle routing, location-allocation,$\backslash$nand multimode resource constrained project scheduling problems are$\backslash$ngiven.},
author = {Kachitvichyanukul, Voratas},
issn = {1598-7248},
journal = {Industrial Engineering and Management Systems},
keywords = {ac,ait,corresponding author,differential evolution,e-mail,evolutionary algorithm,genetic algorithm,particle swarm optimization,th,voratas},
number = {3},
pages = {215--223},
title = {{GA/PSO/DE..Comparison of Three Evolutionary Algorithms: GA, PSO, and DE}},
volume = {11},
year = {2012}
}
@article{GPSO,
author = {Pasupuleti, Srinivas and Battiti, Roberto},
isbn = {1595931864},
journal = {Proceedings of the 8th annual conference on Genetic and evolutionary computation - GECCO '06},
keywords = {differ-,particle swarm algorithm,repeated affine shaker},
number = {0},
pages = {67},
title = {{The gregarious particle swarm optimizer (G-PSO)}},
volume = {1},
year = {2006}
}
@article{OPSO3,
abstract = {Particle Swarm Optimization, a population based optimization technique has been used in wide number of application areas to solve optimization problems. This paper presents a new algorithm for initialization of population in standard PSO called Opposition based Particle Swarm Optimization (O-PSO). The performance of proposed initialization algorithm is compared with the existing PSO variants on several benchmark functions and the experimental results reveal that O-PSO outperforms existing approaches to a large extent.},
author = {Jabeen, Hajira and Jalil, Zunera and Baig, Abdul Rauf},
isbn = {9781605585055},
journal = {Proceedings of the 11th annual conference companion on Genetic and evolutionary computation conference - GECCO '09},
keywords = {initialization,opposition based learning,optimization,pso,swarm intelligence},
pages = {2047},
title = {{Opposition based initialization in particle swarm optimization (O-PSO)}},
year = {2009}
}

@article{PSO_KA,
abstract = {— A new technique titled " Particle Refresh " and a hybridization with conjugate gradient method are introduced to particle swarm optimization (PSO). The former charges power to inactive particle to improve the recovery ability of PSO after trapping on a local solution, and as a result, it becomes easy to choose suitable values for control-parameters to keep high performance for diverse objective functions. On the other hand, the point of the latter is how to determine the changeover timing between a conjugate gradient method and a PSO algorithm.},
author = {Kawakami, K. and Meng, Zhi Qi},
issn = {1931-7360},
journal = {PIERS Online},
keywords = {-component,chain mnagement,ga,genetic algorithm,mutation,particle swarm optimization,pso,sa,scm,stability analysis,supply},
number = {2},
pages = {261--264},
title = {{Improvement of Particle Swarm Optimization}},
volume = {5},
year = {2009}
}

@book{metabook,
author = {Du, Ke-Lin and Swamy, M. N. S.},
isbn = {978-3-319-41191-0},
issn = {3319411926},
pages = {327--336},
title = {{Search and Optimization by Metaheuristics}},
url = {http://link.springer.com/10.1007/978-3-319-41192-7},
year = {2016}
}

@article{oblcpso,
author = {Zhou, Jianhong and Fang, Wei and Wu, Xiaojun and Sun, Jun and Cheng, Shi},
isbn = {9781509006236},
pages = {515--521},
title = {{An Opposition-Based Learning Competitive Particle Swarm Optimizer}},
year = {2016}
}

@article{Algorithm2006,
abstract = {Since their inception nearly 30 years ago, genetic algorithms have evolved like the species they try to mimic. Here, our authors describe how one form of genetic algorithms -- Evolution Strategies -- are significantly faster at numerical optimization than traditional genetic algorithms.},
author = {Algorithm, The},
journal = {Evolution},
title = {{Differential Evolution}},
year = {2006}
}

@article{Whitley1994,
abstract = {This tutorial covers the canonical genetic algorithm as well as more experimental forms of genetic algorithms, including parallel island models and parallel cellular genetic algorithms. The tutorial also illustrates genetic search by hyperplane sampling. The theoretical foun- dations of genetic algorithms are reviewed, include the schema theorem as well as recently developed exact models of the canonical genetic algorithm.},
author = {Whitley, Darrell},
journal = {Statistics and Computing},
keywords = {Genetic algorithms,parallel algorithms,search},
pmid = {848},
title = {{A genetic algorithm tutorial}},
year = {1994}
}

@article{Algorithms2004,
abstract = {A continuous genetic algorithm is described. Several different continuous crossover schemes are described. Differences with the binary genetic algorithm are elucidated. A detailed demonstration problem indicates the excellent convergence of the continuous genetic algorithm.},
author = {Algorithms, Practical Genetic and Edition, Second and Haupt, Rl and Haupt, Se},
journal = {Practical Genetic Algorithms, Second},
title = {{The continuous genetic algorithm}},
year = {2004}
}

@article{Sivanandam2008,
abstract = {These data structures are discussed in the following subsections. 8.2.1 Chromosomes The chromosome data structure stores an entire population in a single matrix of size Nind × Lind, where Nind is the number of individuals in the population and Lind is the length of the genotypic representation of those individuals. Each row corre-sponds to an individual's genotype, consisting of base-n, typically binary, values.},
author = {Sivanandam, Sn and Deepa, Sn},
journal = {Introduction to Genetic Algorithms},
title = {{Genetic Algorithm Implementation Using Matlab}},
year = {2008}
}

@article{Beyer2002,
abstract = {This article gives a comprehensive introduction into one of the main branches of evolutionary computation the evolution strategies (ES) the history of which dates back to the 1960s in Germany. Starting from a survey of history the philosophical background is explained in order to make understandable why ES are realized in the way they are. Basic ES algorithms and design principles for variation and selection operators as well as theoretical issues are presented, and future branches of ES research are discussed.},
author = {Beyer, Hans-georg and Schwefel, Hans-paul},
journal = {Evolutionary Computation},
keywords = {abbreviations,bbh,building block hypothesis,cma,computational intelligence,covariance matrix adaptation,csa,cumulative step size adaptation,darwinian evolution,design principles genetic,ea,ec,evolution strategies,evolutionary,evolutionary algorithm,evolutionary computation,operators,optimization},
title = {{Evolution strategies}},
year = {2002}
}

@inproceedings{Hansen2017,
abstract = {CMA-ES, Covariance Matrix Adaptation Evolution Strategy for non-linear numerical optimization in Python},
author = {Hansen, Nikolaus},
title = {CMA-ES Python package},
year = {2017}
}

@article{Durillo2011,
title = "jMetal: A Java framework for multi-objective optimization",
journal = "Advances in Engineering Software",
volume = "42",
pages = "760-771 ",
year = "2011",
author = "Juan J. Durillo and Antonio J. Nebro",
keywords = "Multi-objective optimization",
keywords = "Metaheuristics",
keywords = "Software tool",
keywords = "Object-oriented architecture",
keywords = "Performance assessment support",
keywords = "Experimentation"
}

@inproceedings{DNA10,
	Address = {Barcelona, Spain},
	Author = { J.J. Durillo and A.J. Nebro and E. Alba  },
	Booktitle = {CEC 2010},
	Month = {July},
	Pages = {4138-4325},
	OPTPublisher = {Springer Berlin / Heidelberg},
	OPTSeries = {Lecture Notes in Computer Science},
	Title = {The jMetal Framework for Multi-Objective Optimization: Design and Architecture},
	OPTVolume = {5467},
	Year = {2010}}

@INBOOK{wagner2014,
  chapter = {Architecture and Design of the HeuristicLab Optimization Environment},
  pages = {197--261},
  title = {Advanced Methods and Applications in Computational Intelligence},
  publisher = {Springer},
  year = {2014},
  editor = {Klempous, Ryszard and Nikodem, Jan and Jacak, Witold and Chaczko,
	Zenon},
  author = {Wagner, Stefan and Kronberger, Gabriel and Beham, Andreas and Kommenda,
	Michael and Scheibenpflug, Andreas and Pitzer, Erik and Vonolfen,
	Stefan and Kofler, Monika and Winkler, Stephan and Dorfer, Viktoria
	and Affenzeller, Michael},
  volume = {6},
  series = {Topics in Intelligent Engineering and Informatics},
  abstract = {Many optimization problems cannot be solved by classical mathematical
	optimization techniques due to their complexity and the size of the
	solution space. In order to achieve solutions of high quality though,
	heuristic optimization algorithms are frequently used. These algorithms
	do not claim to find global optimal solutions, but offer a reasonable
	tradeoff between runtime and solution quality and are therefore especially
	suitable for practical applications. In the last decades the success
	of heuristic optimization techniques in many different problem domains
	encouraged the development of a broad variety of optimization paradigms
	which often use natural processes as a source of inspiration (as
	for example evolutionary algorithms, simulated annealing, or ant
	colony optimization). For the development and application of heuristic
	optimization algorithms in science and industry, mature, flexible
	and usable software systems are required. These systems have to support
	scientists in the development of new algorithms and should also enable
	users to apply different optimization methods on specific problems
	easily. The architecture and design of such heuristic optimization
	software systems impose many challenges on developers due to the
	diversity of algorithms and problems as well as the heterogeneous
	requirements of the different user groups. In this chapter the authors
	describe the architecture and design of their optimization environment
	HeuristicLab which aims to provide a comprehensive system for algorithm
	development, testing, analysis and generally the application of heuristic
	optimization methods on complex problems.},
}

@Article{Cahon2004,
author="Cahon, S.
and Melab, N.
and Talbi, E.-G.",
title="ParadisEO: A Framework for the Reusable Design of Parallel and Distributed Metaheuristics",
journal="Journal of Heuristics",
year="2004",
month="May",
day="01",
volume="10",
number="3",
pages="357--380",
abstract="In this paper, we present the ParadisEO white-box object-oriented framework dedicated to the reusable design of parallel and distributed metaheuristics (PDM). ParadisEO provides a broad range of features including evolutionary algorithms (EA), local searches (LS), the most common parallel and distributed models and hybridization mechanisms, etc. This high content and utility encourages its use at European level. ParadisEO is based on a clear conceptual separation of the solution methods from the problems they are intended to solve. This separation confers to the user a maximum code and design reuse. Furthermore, the fine-grained nature of the classes provided by the framework allow a higher flexibility compared to other frameworks. ParadisEO is of the rare frameworks that provide the most common parallel and distributed models. Their implementation is portable on distributed-memory machines as well as on shared-memory multiprocessors, as it uses standard libraries such as MPI, PVM and PThreads. The models can be exploited in a transparent way, one has just to instantiate their associated provided classes. Their experimentation on the radio network design real-world application demonstrate their efficiency.",
}



@book{eiben,
 author = {Eiben, A. E. and Smith, James E.},
 title = {Introduction to Evolutionary Computing},
 year = {2015},
 isbn = {3662448734, 9783662448731},
 edition = {2nd},
 publisher = {Springer Publishing Company, Incorporated},
} 


@book{search,
 author = {Du, Ke-Lin and Swamy, M. N. S.},
 title = {Search and Optimization by Metaheuristics: Techniques and Algorithms Inspired by Nature},
 year = {2016},
 edition = {1st},
 publisher = {Birkh \& Basel}
} 

@book{metaheuristics,
place={Hoboken},
edition={1},
title={Metaheuristics},
publisher={Wiley},
author={Talbi, El-Ghazali},
year={2009}
}


@INPROCEEDINGS{Moreira2018, 
author={R. P. C. Moreira and E. Wanner and F. V. C. Martins and J. F. M. Sarubbi}, 
booktitle={2018 IEEE Congress on Evolutionary Computation (CEC)}, 
title={An Evolutionary Mono-Objective Approach for Solving the Menu Planning Problem}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={This work proposes an evolutionary approach to solve the Menu Planning Problem. Our work uses the Brazilian school context and our principal goal is to create menus that minimize the total cost of these menus. However, those menus must also satisfy requirements of the Brazilian government, such as: (i) student age group, (ii) school category, (iii) school duration time, (iv) school location, (v) variety of preparations, (vi) harmony of preparations, (vii) maximum amount to be paid for each meal and, (viii) lower and upper limits of macronutrients. The results demonstrate that the evolutionary approach is not only able to generate a set of inexpensive and healthy menus but also respect the required set of constraints. A constrained deterministic approach is performed to generate 5-day menu through a greedy-based function taking into account the normalized sum of all macronutrients and the monetary cost of the menu. A comparison between the 5-day menu obtained by the proposed approach and the constrained greedy-based approach menu is carried out. Despite the fact the obtained menu outperforms the greed-based menu taking into account the total cost, this difference is not so expressive. However, all macronutrients were outside the pre-defined range at least in one day of the week. The 5-day menu obtained by the proposed approach is evaluated by a nutritionist. The overall quality of the menu is outstanding and the time spent to generate it is 60 seconds.}, 
keywords={costing;educational administrative data processing;educational institutions;evolutionary computation;greedy algorithms;planning;menu planning problem;constrained greedy-based approach menu;monetary cost;greedy-based function;5-day menu;constrained deterministic approach;healthy menus;inexpensive menus;macronutrients;school location;school duration time;school category;student age group;Brazilian government;total cost;Brazilian school context;evolutionary mono-objective approach;Planning;Obesity;Genetic algorithms;Lips;Fats;Proteins;Government;Menu Planning;School Feeding;Evolutionary Computation;Single-objective optimization}, 
doi={10.1109/CEC.2018.8477888}, 
ISSN={}, 
month={July},}

@article{Ngo2016,
abstract = {Planning is widely been used in many areas such as in medicine, administration, business, logistics, education, environment and family matters. In automated planning research, the word},
author = {Ngo, Hea Choon and Cheah, Yu-N and Goh, Ong Sing and Choo, Yun-Huoy and Basiron, Halizah and Kumar, Yogan Jaya and Ngo, Hea Choon and Cheah, Yu-N and Goh, Ong Sing and Choo, Yun-Huoy and Basiron, Halizah and Kumar, Yogan Jaya},
issn = {1549-3636},
journal = {Journal of Computer Science},
keywords = {Agents,Automated Planning,Constraints,Menu Planning,Nutrition Care Expert Systems},
month = {dec},
number = {12},
pages = {582--596},
publisher = {Science Publications},
title = {{A Review on Automated Menu Planning Approaches}},
volume = {12},
year = {2016}
}

@article{Funabiki2011,
abstract = {For busy persons such as working people, students, and nurturing parents, it is very hard to spend a long time in cooking foods by themselves at home after working for long hours on weekdays. As one solution, the cooking process can be divided into two phases, where the preparation steps for foods that they will eat on the following weekdays are performed on a weekend, and the final steps for some foods are finished on the eating day in a short time. Then, the task of generating a menu planning with this two-phase cooking becomes a complex problem to satisfy the limited cooking time. In this paper, we formulate this time-constrained menu planning problem with the two-phase cooking, and prove the NP-completeness of its decision problem through the reduction from the NP-complete knapsack problem. Then, we present its heuristic algorithm based on a simple greedy method for the knapsack problem, where foods are sequentially selected into the menu in descending order of food priorities. We apply the algorithm to the generation of one week menu plan from 53 food candidates, where the result verifies the effectiveness of our approach. {\textcopyright} 2011 IEEE.},
author = {Funabiki, Nobuo and Taniguchi, Shiho and Matsushima, Yukiko and Nakanishi, Toru},
isbn = {9780769543734},
journal = {Proceedings of the International Conference on Complex, Intelligent and Software Intensive Systems, CISIS 2011},
keywords = {Menu planning,algorithm,finishing phase,preparation phase,two-phase cooking},
pages = {668--673},
title = {{A proposal of a menu planning algorithm for two-phase cooking by busy persons}},
year = {2011}
}

@article{Sufahani2014,
abstract = {Humans need to eat a good and balanced nutritious diet that provides calories for energy requirements and nutrients for proper growth, repair and maintenance of the body tissues. Moreover, it is essential for resisting and preventing diseases and infection that may lead to problems such as anemia, scurvy and rickets. In recent studies, medical researchers have discovered that good nutrition can help to reduce the risks of coronary heart disease and certain types of cancer. Menu and diet planners face tremendous challenges and difficulties in order to improve human health. Serving healthier meals is a major step towards achieving that objective. However, constructing and planning a nutritious and balanced menu manually is complicated, inefficient and time-consuming. The aim of this study is to develop a mathematical model for diet planning that meets the necessary nutrient intake for the secondary school student as well as minimizing a budget. The data were collected from various boarding schools and also from the Ministry of Education. Nutrition planning is a well-known optimization problem and the goal is to find the best possible optimal solution. Therefore the model was solved by using optimization method along with Integer Programming. This model can be adopted to solve other diet planning problems such as for the military, hospitals nursing home and universities.},
author = {Sufahani, Suliadi and Ismail, Zuhaimy},
issn = {13147552},
journal = {Applied Mathematical Sciences},
keywords = {decision making,health management,integer,linear programming,mathematical modeling,menu planning,optimization},
number = {151},
pages = {7511--7518},
title = {{A new menu planning model for Malaysian secondary schools using optimization approach}},
url = {http://www.m-hikari.com/ams/ams-2014/ams-149-152-2014/49725.html},
volume = {8},
year = {2014}
}

@article{Zhang2007,
abstract = {Decomposition is a basic strategy in traditional multiobjective optimization. However, it has not yet been widely used in multiobjective evolutionary optimization. This paper proposes a multiobjective evolutionary algorithm based on decomposition (MOEA/D). It decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Each subproblem is optimized by only using information from its several neighboring subproblems, which makes MOEA/D have lower computational complexity at each generation than MOGLS and nondominated sorting genetic algorithm II (NSGA-II). Experimental results have demonstrated that MOEA/D with simple decomposition methods outperforms or performs similarly to MOGLS and NSGA-II on multiobjective 0-1 knapsack problems and continuous multiobjective optimization problems. It has been shown that MOEA/D using objective normalization can deal with disparately-scaled objectives, and MOEA/D with an advanced decomposition method can generate a set of very evenly distributed solutions for 3-objective test instances. The ability of MOEA/D with small population, the scalability and sensitivity of MOEA/D have also been experimentally investigated in this paper.},
archivePrefix = {arXiv},
arxivId = {1701.00879},
author = {Zhang, Qingfu and Li, Hui},
eprint = {1701.00879},
isbn = {1089-778X VO - 11},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Computational complexity,Decomposition,Evolutionary algorithm,Multiobjective optimization,Pareto optimality},
number = {6},
pages = {712--731},
pmid = {10516012},
title = {{MOEA/D: A multiobjective evolutionary algorithm based on decomposition}},
volume = {11},
year = {2007}
}

@article{Ma2018,
author = {Ma, Xiaoliang and Zhang, Qingfu and Tian, Guangdong and Yang, Junshan and Zhu, Zexuan},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {R2 metric,Tchebycheff decomposition.,maximal fitness improvement,multiobjective evolutionary algorithm based on decomposition (MOEA/D,population update strategy},
number = {2},
pages = {226--244},
title = {{On Tchebycheff Decomposition Approaches for Multiobjective Evolutionary Optimization}},
volume = {22},
year = {2018}
}

@ARTICLE{996017, 
author={K. Deb and A. Pratap and S. Agarwal and T. Meyarivan}, 
journal={IEEE Transactions on Evolutionary Computation}, 
title={A fast and elitist multiobjective genetic algorithm: NSGA-II}, 
year={2002}, 
volume={6}, 
number={2}, 
pages={182-197}, 
keywords={genetic algorithms;operations research;computational complexity;Pareto distribution;simulation;convergence;constraint theory;sorting;fast elitist multi-objective genetic algorithm;NSGA-II;Nondominated Sorting Genetic Algorithm II;multi-objective evolutionary algorithm;nondominated sharing;computational complexity;objectives;population size;selection operator;mating pool;parent/offspring population combination;solution fitness;solution spread;simulation;convergence;Pareto-optimal front;Pareto-archived evolution strategy;strength-Pareto evolutionary algorithm;dominance definition;constrained multi-objective problems;nonlinear problem;multi-objective optimization;algorithm performance;constraint handling;multi-criterion decision making;Genetic algorithms;Sorting;Computational complexity;Evolutionary computation;Computational modeling;Testing;Decision making;Associate members;Diversity reception;Constraint optimization}, 
doi={10.1109/4235.996017}, 
ISSN={1089-778X}, 
month={April},}

@inproceedings{Laumanns2001SPEA2,
  title={SPEA 2 : Improving the strength pareto evolutionary algorithm},
  author={Marco Laumanns},
  year={2001}
}

@article{Srinivas1994MuiltiobjectiveOU,
  title={Muiltiobjective Optimization Using Nondominated Sorting in Genetic Algorithms},
  author={N. Srinivas and Kalyanmoy Deb},
  journal={Evolutionary Computation},
  year={1994},
  volume={2},
  pages={221-248}
}