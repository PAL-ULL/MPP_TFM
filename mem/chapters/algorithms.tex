
At this point, it will be introduced the evolutionary algorithms compared in this thesis. With a view to have variety of MOEAs, every algorithm it is based on a different MOEA approach\cite{ZHOU201132}:

\begin{itemize}
    \item Based on decomposition: Multi-objective Evolutionary Algorithm Based on Decomposition.
    \item Based on preference: Non-dominated Sorting Genetic Algorithm II.
    \item Based on PSO: Strength Pareto Evolutionary Algorithm 2. 
\end{itemize}

\section{Multi-objective Evolutionary Algorithm Based on Decomposition}
Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D) is an evolutionary algorithm for multi-objective optimisation proposed by Qingfu Zhang and Hui Li in 2007\cite{Zhang2007}. The underlying idea behind this algorithm is to decompose a multi-objective optimisation problem into a number of scalar optimisation sub-problems and optimises them simultaneously. It also harnesses in the well-known feature of Pareto optimal solutions to a MOP, which sustains that an optimal solution for a scalar optimisation problem with an objective function as the aggregation of all the $f_{i}$ could be the same as the Pareto optimal solution for the MOP\cite{Zhang2007}.

The decomposition approach of MOEA/D takes place where the algorithm decomposes a MOP into \textit{N} sub-problems and simultaneously optimises every single sub-problem at each generation. Furthermore it establish some relations between sub-problems and organised them in neighbourhoods. These neighbourhoods are shaped by sub-problems which coefficient vectors are very similar to each other and every single sub-problem is optimised based on its neighbouring sub-problems information. Therefore, the optimal solution for two neighbouring sub-problems should be very similar\cite{Zhang2007}.

On the other hand, the process of decompose a MOP into \textit{N} sub-problems can be done from some different approaches. However, as the authors referred\cite{Zhang2007} it this paper the MOEA/D uses the Tchebycheff Approach\cite{Ma2018} to decompose a MOP. Formally, the Tchebycheff Approach it is defined as follows:
\[
min\quad g^{te}(x|\lambda,z^{*}) = max_{i=1}^{m}\{\lambda_{i}|f_{i}(x)-z_{i}^{*}|\}
\]

where $z^{*} = (z^{*}_{1}, ..., z^{*}_{m})$ is the reference point with the best solution founds so far for each sub-problem and $\lambda_{i} = (\lambda_{i,1}, ..., \lambda_{i,m})$ is a even spread weight vector for each sub-problem \textit{i}.

In addition, MOEA/D version implemented in this paper works as follows. It takes a MOP, the population size, a stopping criterion and the number of neighbours for each neighbourhood. The number of sub-problems in this implementation are the MOP's objectives. Then, it starts by randomly generate \textit{N} even spread weight vectors and compute the Euclidean distance between each others to shape the neighbourhoods, generates an initial random population and computes the reference point $Z^{*}$. After the initialisation phase, it goes into the main loop where, until the stopping criteria is not satisfied, the algorithm preforms theses steps for each individual of the population:
\begin{itemize}
  \item Reproduction: generates a new child individual from two randomly selected neighbours \textit{l, k}.
  \item Improve: maintains the new child under the limits of the problem's search space.
  \item UpdateZ: updates the reference point by comparing it with each new child individual.
  \item Update Neighbours: if the new child individual performs better than any neighbours, replaces the neighbour with the brand new individual.
\end{itemize}
Finally, MOEA/D returns the PF's points found. \\

Concretely, the algorithm can be outlined as follows: \\

\begin{algorithm}[H]
\begin{algorithmic}[1]
 % \KwData{MOP, PopSize, StopCriteria, Neighbours}
  %\KwResult{PF}
  \State SetRandomWeightVectors()\;
  \State EuclideanDistance()\;
  \State GenerateRandomPopulation()\;
  \State InitializeZ()\;
  \While{not StopCriteria satisfied}
    \ForAll{sub-problem}
      \State l,k = getRandomNeigbours()\;
      \State child = reproduce(l, k)\;
      \State child = improve(child)\;
      \State updateZ(child)\;
      \State updateNeighbouringSolutions(child)\;
    \EndFor 
    \EndWhile
    \State \textbf{end}
\end{algorithmic}
\caption{MOEA/D version of this thesis.}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Nondominated Sorting Genetic~Algorithm~II}
\textit{Nondominated Sorting Genetic Algorithm II}, as well known as \textit{NSGA-II} was proposed in 2002 by K. Deb and A. Pratap and S. Agarwal and T. Meyarivan to mitigate the major difficulties of nondominated sorting MOEAs\cite{996017}. In fact, this algorithm is an improvement of the previously algorithm is an improvement of the previously suggested algorithm NSGA [16] algorithm NSGA\cite{Srinivas1994MuiltiobjectiveOU} in 1994 by N. Srinivas and Kalyanmoy Deb.
The main improvements of NSGA-II over NSGA is a fast nondominated sorting approach with complexity $\mathcal{O}(MN^{2})$ that replaces the previous one which has complexity $\mathcal{O}(MN^{3})$\cite{996017}(considering \textit{M} the number of objectives and \textit{N} the population size) and the selection operator of NSGA-II which comes to solve the lack of elitism of the previous NSGA version. The fast nondominated sorting procedure starts by computing the domination count $n_{p}$ which is the number of solutions that dominates \textit{p} and next, the set of solutions dominated by p called \textit{$S_{p}$}. Then the procedure continues identifying all Pareto Fronts and ranking the solutions in different fronts by its $n_{p}$\cite{996017} .

NSGA-II algorithm is quite simple and it can be seen in the pseudocode down below.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\State P = CreateInitialPopulation(N)\;
\State  FastNondominatedSorting(P)\;
  \While{not StopCriteria satisfied}
    \State BinaryTournamentSelection(P)\;
    \State Q = CreateOffspring(P)\;
    \State R = Combine(P, Q)\;
    \State FastNondominatedSorting(R)\;
    \State P = SelectNIndividuals(R, N)\;
  \EndWhile
  \State \textbf{end}
\end{algorithmic}
\caption{Pseudocode of NSGA-II.}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Strength Pareto Evolutionary Algorithm 2}
Likewise \textit{NSGA-II} is an improvements of its predecessor NSGA, the \textit{Strength Pareto Evolutionary Algorithm 2} was published in 2001 by Eckart Zitzler, Marco Laumanns and Lothar Thiele as a new version of SPEA algorithm proposed in 1999 by Zitzler and Thiele\cite{SPEA2}.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\State P = CreateInitialPopulation(N)\;
\State $\overline{P}$ = CreateEmptyArchive();\;
  \While{not StopCriteria satisfied}
    \State ComputeFitness(P,$\overline{P}$)
    \State EnvironmentalSelection();
    \State BinaryTournamentSelection();
    \State Recombination();
    \State Mutation();
  \EndWhile
  \State \textbf{end}
\end{algorithmic}
\caption{Pseudocode of SPEA2.}
\end{algorithm}