
At this point, it will be introduced the evolutionary algorithms compared in this thesis. With a view to have variety of MOEAs, every algorithm it is based on a different MOEA approach\cite{ZHOU201132}:

\begin{itemize}
    \item Based on decomposition: Multi-objective Evolutionary Algorithm Based on Decomposition.
    \item Based on preference: Non-dominated Sorting Genetic Algorithm II.
    \item Based on PSO: Strength Pareto Evolutionary Algorithm 2. 
\end{itemize}

\section{Multi-objective Evolutionary Algorithm Based on Decomposition}
Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D) is an evolutionary algorithm for multi-objective optimisation proposed by Qingfu Zhang and Hui Li in 2007\cite{Zhang2007}. The underlying idea behind this algorithm is to decompose a multi-objective optimisation problem into a number of scalar optimisation sub-problems and optimises them simultaneously. It also harnesses in the well-known feature of Pareto optimal solutions to a MOP, which sustains that an optimal solution for a scalar optimisation problem with an objective function as the aggregation of all the $f_{i}$ could be the same as the Pareto optimal solution for the MOP\cite{Zhang2007}.

The decomposition approach of MOEA/D takes place where the algorithm decomposes a MOP into \textit{N} sub-problems and simultaneously optimises every single sub-problem at each generation. Furthermore it establish some relations between sub-problems and organised them in neighbourhoods. These neighbourhoods are shaped by sub-problems which coefficient vectors are very similar to each other and every single sub-problem is optimised based on its neighbouring sub-problems information. Therefore, the optimal solution for two neighbouring sub-problems should be very similar\cite{Zhang2007}.

On the other hand, the process of decompose a MOP into \textit{N} sub-problems can be done from some different approaches. However, as the authors referred\cite{Zhang2007} it this paper the MOEA/D uses the Tchebycheff Approach\cite{Ma2018} to decompose a MOP. Formally, the Tchebycheff Approach it is defined as follows:
\[
min\quad g^{te}(x|\lambda,z^{*}) = max_{i=1}^{m}\{\lambda_{i}|f_{i}(x)-z_{i}^{*}|\}
\]

where $z^{*} = (z^{*}_{1}, ..., z^{*}_{m})$ is the reference point with the best solution founds so far for each sub-problem and $\lambda_{i} = (\lambda_{i,1}, ..., \lambda_{i,m})$ is a even spread weight vector for each sub-problem \textit{i}.

In addition, MOEA/D version implemented in this paper works as follows. It takes a MOP, the population size, a stopping criterion and the number of neighbours for each neighbourhood. The number of sub-problems in this implementation are the MOP's objectives. Then, it starts by randomly generate \textit{N} even spread weight vectors and compute the Euclidean distance between each others to shape the neighbourhoods, generates an initial random population and computes the reference point $Z^{*}$. After the initialisation phase, it goes into the main loop where, until the stopping criteria is not satisfied, the algorithm preforms theses steps for each individual of the population:
\begin{itemize}
  \item Reproduction: generates a new child individual from two randomly selected neighbours \textit{l, k}.
  \item Improve: maintains the new child under the limits of the problem's search space.
  \item UpdateZ: updates the reference point by comparing it with each new child individual.
  \item Update Neighbours: if the new child individual performs better than any neighbours, replaces the neighbour with the brand new individual.
\end{itemize}
Finally, MOEA/D returns the PF's points found. \\

Concretely, the algorithm can be outlined as follows: \\

\begin{algorithm}[H]
\begin{algorithmic}[1]
 % \KwData{MOP, PopSize, StopCriteria, Neighbours}
  %\KwResult{PF}
  \State SetRandomWeightVectors()\;
  \State EuclideanDistance()\;
  \State GenerateRandomPopulation()\;
  \State InitializeZ()\;
  \While{not StopCriteria satisfied}
    \ForAll{sub-problem}
      \State l,k = getRandomNeigbours()\;
      \State child = reproduce(l, k)\;
      \State child = improve(child)\;
      \State updateZ(child)\;
      \State updateNeighbouringSolutions(child)\;
    \EndFor 
    \EndWhile
    \State \textbf{end}
\end{algorithmic}
\caption{MOEA/D version of this thesis.}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Nondominated Sorting Genetic~Algorithm~II}
\textit{Nondominated Sorting Genetic Algorithm II}, as well known as \textit{NSGA-II} was proposed in 2002 by K. Deb and A. Pratap and S. Agarwal and T. Meyarivan to mitigate the major difficulties of nondominated sorting MOEAs\cite{996017}. In fact, this algorithm is an improvement of the previously algorithm is an improvement of the previously suggested algorithm NSGA [16] algorithm NSGA\cite{Srinivas1994MuiltiobjectiveOU} in 1994 by N. Srinivas and Kalyanmoy Deb.
The main improvements of NSGA-II over NSGA is a fast nondominated sorting approach with complexity $\mathcal{O}(MN^{2})$ that replaces the previous one which has complexity $\mathcal{O}(MN^{3})$\cite{996017}(considering \textit{M} the number of objectives and \textit{N} the population size) and the selection operator of NSGA-II which comes to solve the lack of elitism of the previous NSGA version. The fast nondominated sorting procedure starts by computing the domination count $n_{p}$ which is the number of solutions that dominates \textit{p} and next, the set of solutions dominated by p called \textit{$S_{p}$}. Then the procedure continues identifying all Pareto Fronts and ranking the solutions in different fronts by its $n_{p}$\cite{996017} .

NSGA-II algorithm is quite simple and it can be seen in the pseudocode down below.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\State P = CreateInitialPopulation(N)\;
\State  FastNondominatedSorting(P)\;
  \While{not StopCriteria satisfied}
    \State BinaryTournamentSelection(P)\;
    \State Q = CreateOffspring(P)\;
    \State R = Combine(P, Q)\;
    \State FastNondominatedSorting(R)\;
    \State P = SelectNIndividuals(R, N)\;
  \EndWhile
  \State \textbf{end}
\end{algorithmic}
\caption{Pseudocode of NSGA-II.}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Strength Pareto Evolutionary Algorithm 2}
Likewise \textit{NSGA-II} is an improvement of its predecessor NSGA, the \textit{Strength Pareto Evolutionary Algorithm 2} was published in 2001 by Eckart Zitzler, Marco Laumanns and Lothar Thiele as a new version of SPEA algorithm proposed in 1999 by Zitzler and Thiele\cite{SPEA2}. Essentially, the SPEA 2 differs with SPEA in a fine-grained fitness assignment strategy, a density estimation technique, and an enhanced archive truncation method\cite{SPEA2}.
The basis of both SPEA and SPEA 2 algorithm are that they uses a standard population (P) and also an \textit{archive ($\overline{P}$)} or external population and follows theses steps:
\begin{itemize}
    \item Create an initial random population of size \textit{N} and an empty archive.
    \item Then all nondominated individuals are sent to the archive.
    \item If the size of the archive increase over the limit $\overline{N}$, new archive individuals are deleted preserving the nondominated front.
    \item Both population and archive individuals are evaluated and a fitness value is assigned to each of them.
    \item After the evaluation, the mating selection phase comes.
    \item When the parents are selected, genetic operators are applied to generate offspring and replace the old population.
\end{itemize}

Although those are the foundations of SPEA and SPEA 2, SPEA 2 has two improvements in \textit{fitness assignment} and \textit{environmental selection}.
On the one hand, in an effort to avoid that individuals dominated by the same archive individuals have the same fitness, each individual \textbf{i} in $\overline{P}$ and P have a strength value $S(i)$ indicating the number of individuals it dominates\cite{SPEA2}.
\[
    S(i) = | \{ j | j \in P_{t} + \overline{P_{t}} \land	 i \succ j \} |
\]
After computing the strength of each individual, a \textit{Raw fitness value (R)} is calculated for each individual.
\[
    R(i) = \sum_{j\in P_{t} + \overline{P_{t}}, j \succ i}{S(j)}
\]
In the case where most individuals do not dominate each other, \textit{R} it is not enough so an adaptation of the \textit{k}-the nearest neighbour algorithm is included for additional density information. In this particular case, authors use k as the result of the square root of the sample size, so $k = \sqrt{N + \overline{N}}$. Then, the density of each individual is calculated as follows.
\[
    D(i) = \frac{1}{\sigma_{i}^{k} + 2}
\]
Finally, the fitness value (\textit{F}) of each individual is defined as the sum of its raw fitness plus its density.
\[
    F(i) = R(i) + D(i)
\]
On the other hand, the archive updating procedure of SPEA 2 is slightly different from SPEA. Primarily, it ensures two aspects\cite{SPEA2}: 
\begin{itemize}
    \item The number of individuals in the archive maintain is regular.
    \item The truncation method prevents boundary solutions being removed.
\end{itemize}
The environmental selection begins by copying all nondominated individuals from archive and population which have a fitness value \textit{F} lower than one to the archive for the next generation.
\[
\overline{P_{t+1}} = \{ i | i \in \overline{P_{t}} + \overline{P_{t}} \land F(i) < 1 \}
\]
After finishing this step, if the archive is fully filling, the environmental selection is completed. Under other conditions, new individuals are added to the archive if it is too small or deleted in other case to fit the size $\overline{N}$.

All the previous description of SPEA 2 algorithm can be outlined in the following pseudocode.
\begin{algorithm}[H]
\begin{algorithmic}[1]
\State P = CreateInitialPopulation(N)\;
\State $\overline{P}$ = CreateEmptyArchive();\;
  \While{not StopCriteria satisfied}
    \State ComputeFitness(P,$\overline{P}$)
    \State EnvironmentalSelection();
    \State BinaryTournamentSelection();
    \State Recombination();
    \State Mutation();
  \EndWhile
  \State \textbf{end}
\end{algorithmic}
\caption{Pseudocode of SPEA2.}
\end{algorithm}